{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Introduction to Machine Learning\"\n",
        "subtitle: \"Core Concepts and First Examples\"\n",
        "author: \"Miguel Fonseca\"\n",
        "format:\n",
        "  revealjs\n",
        "#     theme: simple\n",
        "#     slide-number: true\n",
        "#     transition: fade\n",
        "#     code-line-numbers: true\n",
        "# execute:\n",
        "#   echo: true\n",
        "#   warning: false\n",
        "#   message: false\n",
        "---\n",
        "\n",
        "# Definition\n",
        "\n",
        "## What is Machine Learning? {.scrollable}\n",
        "\n",
        "<!-- **Machine Learning (ML)** -->\n",
        "<!-- is a branch of Artificial Intelligence that focuses on: -->\n",
        "\n",
        ":::{.callout title=\"Machine Learning (ML)\"}\n",
        "Algorithms that learn patterns from data and make predictions or decisions without being explicitly programmed.\n",
        ":::\n",
        "\n",
        "Examples:\n",
        "\n",
        "- Email spam detection\n",
        "- Credit risk assessment\n",
        "- Image and speech recognition\n",
        "- Recommendation systems\n",
        "\n",
        "<!-- ## Why Machine Learning?\n",
        "\n",
        "Traditional programming:\n",
        "\n",
        "- Rules are **explicitly coded**\n",
        "- Hard to scale for complex patterns\n",
        "\n",
        "Machine learning:\n",
        "\n",
        "- Rules are **learned from data**\n",
        "- Scales well to high-dimensional problems\n",
        "- Adapts as more data becomes available\n",
        "\n",
        "--- -->\n",
        "## Machine Learning vs. Statistics {.scrollable} \n",
        "\n",
        "| Aspect                | Statistics                                              | Machine Learning                                         |\n",
        "| --------------------- | ------------------------------------------------------- | -------------------------------------------------------- |\n",
        "| **Primary goal**      | Inference, explanation, uncertainty quantification      | Prediction, pattern discovery, automation                |\n",
        "| **Typical questions** | *Why does this happen?*<br>*Is the effect significant?* | *What will happen next?*<br>*Can we predict accurately?* |\n",
        "| **Model assumptions** | Strong (distributional forms, linearity, independence)  | Often weak or implicit                                   |\n",
        "| **Data size**         | Small to moderate datasets                              | Large, high-dimensional datasets                         |\n",
        "<!-- | **Interpretability**  | High (coefficients, confidence intervals, p-values)     | Varies (from linear models to black boxes)               | -->\n",
        "| **Evaluation**        | Hypothesis tests, confidence intervals                  | Train/validation/test split, predictive metrics          |\n",
        "<!-- | **Typical methods**   | Linear regression, hypothesis testing, ANOVA            | Trees, random forests, neural networks                   | -->\n",
        "| **Philosophy**        | Model the data-generating process                       | Optimize performance on unseen data                      |\n",
        "\n",
        "\n",
        "## Main Categories of Machine Learning {.scrollable}\n",
        "\n",
        "### 1. Supervised Learning\n",
        "- Data with **labels**\n",
        "- Learn input → output mapping\n",
        "\n",
        "### 2. Unsupervised Learning\n",
        "- Data **without labels**\n",
        "- Discover hidden structure\n",
        "\n",
        "(We will focus mainly on supervised learning.)\n",
        "\n",
        "---\n",
        "\n",
        "## Supervised Learning {.scrollable}\n",
        "\n",
        "Each observation consists of:\n",
        "\n",
        "- **Features** $X$\n",
        "- **Target** $y$\n",
        "\n",
        "Goal:\n",
        "$$\n",
        "f(X) \\approx y\n",
        "$$\n",
        "\n",
        "Typical applications:\n",
        "\n",
        "- Predict prices\n",
        "- Classify emails\n",
        "- Diagnose diseases\n",
        "\n",
        "# Supervised Learning\n",
        "\n",
        "## Supervised Learning Tasks {.scrollable}\n",
        "\n",
        "### Two main task types:\n",
        "\n",
        "| Task | Output |\n",
        "|----|----|\n",
        "| **Regression** | Continuous value |\n",
        "| **Classification** | Discrete class |\n",
        "\n",
        "---\n",
        "\n",
        "## Regression {.scrollable}\n",
        "\n",
        "**Regression** predicts a numerical value.\n",
        "\n",
        "Examples:\n",
        "\n",
        "- House price prediction\n",
        "- Stock return forecasting\n",
        "- Temperature prediction\n",
        "\n",
        "Typical models:\n",
        "\n",
        "- Linear Regression\n",
        "- Ridge / Lasso\n",
        "- Random Forest Regressor\n",
        "\n",
        "---\n",
        "\n",
        "## Classification {.scrollable}\n",
        "\n",
        "**Classification** predicts a category or label.\n",
        "\n",
        "Examples:\n",
        "\n",
        "- Spam vs non-spam\n",
        "- Fraud vs non-fraud\n",
        "- Disease vs healthy\n",
        "\n",
        "Typical models:\n",
        "\n",
        "- Logistic Regression\n",
        "- k-Nearest Neighbors\n",
        "- Decision Trees\n",
        "- Support Vector Machines\n",
        "\n",
        "# Unsupervised Learning \n",
        "\n",
        "## Unsupervised Learning {.scrollable}\n",
        "\n",
        "No labeled output variable.\n",
        "\n",
        "Goals:\n",
        "\n",
        "- Discover structure\n",
        "- Group similar observations\n",
        "- Reduce dimensionality\n",
        "\n",
        "Examples:\n",
        "\n",
        "- Customer segmentation\n",
        "- Topic modeling\n",
        "- Data visualization\n",
        "\n",
        "---\n",
        "\n",
        "## Unsupervised Learning Tasks {.scrollable}\n",
        "\n",
        "Common tasks:\n",
        "\n",
        "- **Clustering** (e.g. k-means)\n",
        "- **Dimensionality reduction** (e.g. PCA)\n",
        "\n",
        "Typical use cases:\n",
        "\n",
        "- Exploratory data analysis\n",
        "- Preprocessing\n",
        "- Feature engineering\n",
        "\n",
        "# Machine Learning Workflow\n",
        "\n",
        "## The Machine Learning Workflow {.scrollable}\n",
        "\n",
        "1. Collect data  \n",
        "2. Clean and preprocess  \n",
        "3. Split data  \n",
        "4. Train model  \n",
        "5. Evaluate model  \n",
        "6. Improve / deploy  \n",
        "\n",
        "# Train, Validation & Test\n",
        "\n",
        "## Data Splitting {.scrollable}\n",
        "\n",
        "We typically split data into:\n",
        "\n",
        "- **Training set** – used to fit the model  \n",
        "- **Validation set** – used for model selection / tuning  \n",
        "- **Test set** – used for final evaluation  \n",
        "\n",
        "---\n",
        "\n",
        "## Why Not Train on all Data? {.scrollable}\n",
        "\n",
        "If we train and evaluate on the same data:\n",
        "\n",
        "- Model may **memorize** the data\n",
        "- Performance estimate becomes **optimistic**\n",
        "\n",
        "This is called **overfitting**.\n",
        "\n",
        "---\n",
        "\n",
        "## Train / Validation / Test Split {.scrollable}\n",
        "\n",
        "Typical split ratios:\n",
        "\n",
        "- 60% train / 20% validation / 20% test\n",
        "- or 70% / 15% / 15%\n",
        "\n",
        ":::{.callout title=\"Key principle:\"}\n",
        "The test set must remain untouched until the very end.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Example: Data Splitting in Python {.scrollable}"
      ],
      "id": "434b58f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Dummy data\n",
        "X = np.random.rand(100, 2)\n",
        "y = np.random.rand(100)\n",
        "\n",
        "# Train + test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train + validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "id": "e8e3bf56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# K-Fold Cross-Validation\n",
        "\n",
        "## Motivation {.scrollable}\n",
        "\n",
        "### Why Do We Need Cross-Validation?\n",
        "\n",
        "- Goal: **estimate generalization performance**\n",
        "- Training error is **optimistically biased**\n",
        "- Single train/test split:\n",
        "  - High variance\n",
        "  - Sensitive to random split\n",
        "\n",
        "**Cross-validation reduces uncertainty in model evaluation**\n",
        "\n",
        "---\n",
        "\n",
        "## The Core Idea {.scrollable}\n",
        "\n",
        "### What Is k-Fold Cross-Validation?\n",
        "\n",
        "1. Split data into **k approximately equal folds**\n",
        "2. For each fold:\n",
        "   - Train on `k−1` folds\n",
        "   - Test on the remaining fold\n",
        "3. Aggregate performance metrics\n",
        "\n",
        "$$\n",
        "\\text{CV score} = \\frac{1}{k} \\sum_{i=1}^{k} \\text{Score}_i\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## Choosing k {.scrollable}\n",
        "\n",
        "### Bias–Variance Trade-off\n",
        "\n",
        "| k | Characteristics |\n",
        "|--|--|\n",
        "| 2–5 | Higher bias, lower variance |\n",
        "| 5–10 | Common practical choice |\n",
        "| n (LOOCV) | Minimal bias, high variance & cost |\n",
        "\n",
        "::: {.callout-tip icon=\"false\" title=\"Rule of thumb\"}\n",
        "- k = 5 or 10 for most problems\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Formal Perspective {.scrollable}\n",
        "\n",
        "### Expected Error Estimation\n",
        "\n",
        "k-fold CV estimates:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}_{(X,Y)}[L(f_{\\mathscr{D}}, (X,Y))]\n",
        "$$\n",
        "\n",
        "with:\n",
        "\n",
        "- Different training sets $\\mathscr{D}$\n",
        "- Same learning algorithm\n",
        "- Same data distribution\n",
        "\n",
        "---\n",
        "\n",
        "## Regression vs Classification {.scrollable}\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "| Aspect | Regression | Classification |\n",
        "|--|--|--|\n",
        "| Metrics | MSE, MAE, R² | Accuracy, F1, AUC |\n",
        "| Splits | Random OK | Must preserve class balance |\n",
        "| CV variant | KFold | Stratified k-Fold |\n",
        "\n",
        "---\n",
        "\n",
        "## Regression: k-Fold CV {.scrollable}\n",
        "\n",
        "### Typical Metrics\n",
        "\n",
        "- Mean Squared Error (MSE)\n",
        "- Mean Absolute Error (MAE)\n",
        "- $R^2$\n",
        "\n",
        "::: {.callout-note}\n",
        "Scores may be **negative** in scikit-learn (loss convention)\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Regression Example (scikit-learn) {.scrollable}"
      ],
      "id": "63580bf4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = cross_val_score(\n",
        "    model, X, y,\n",
        "    cv=cv,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "mse_scores = -scores\n",
        "print(\"MSE per fold:\", mse_scores)\n",
        "print(\"Mean MSE:\", mse_scores.mean())"
      ],
      "id": "cb0c76a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Classification: Stratified k-Fold CV {.scrollable}\n",
        "\n",
        "### Why Stratified k-Fold?\n",
        "\n",
        "In classification:\n",
        "\n",
        "- Preserves class proportions in each fold\n",
        "- Especially important for imbalanced datasets\n",
        "\n",
        "Use:\n",
        "\n",
        "- `KFold` → regression\n",
        "- `StratifiedKFold` → classification\n",
        "\n",
        "---\n",
        "\n",
        "## Classification Example"
      ],
      "id": "cba5df28"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=500,\n",
        "    n_features=5,\n",
        "    n_classes=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = cross_val_score(\n",
        "    model, X, y,\n",
        "    cv=skf,\n",
        "    scoring=\"accuracy\"\n",
        ")\n",
        "\n",
        "scores"
      ],
      "id": "d883ade1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Best Practices in CV\n",
        "\n",
        "Cross-validation is often used to:\n",
        "\n",
        "- Compare models\n",
        "- Tune hyperparameters\n",
        "\n",
        "::: {.callout-warning}\n",
        "Cross-Validation $\\neq$ Test Set\n",
        ":::\n",
        "\n",
        ":::{.callout-important title=\"Important Rule\"}\n",
        "Never touch the test set until the very end\n",
        ":::\n",
        "\n",
        "- CV is for model selection\n",
        "- Test set is for final evaluation"
      ],
      "id": "09205c7c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/miguelfonseca/venvs/agrn/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}